# =============================================================================
# DSDM Agents - Environment Configuration
# =============================================================================
# Copy this file to .env and add your credentials
#
# Quick Start:
#   1. Copy: cp .env.example .env
#   2. Set your preferred LLM provider (anthropic, openai, gemini, or ollama)
#   3. Add the API key for your chosen provider
#   4. (Optional) Configure Jira/Confluence for project management integration

# =============================================================================
# LLM Provider Selection (Required)
# =============================================================================
# Select which LLM provider to use: anthropic, openai, gemini, ollama
# Default: anthropic
LLM_PROVIDER=anthropic

# =============================================================================
# Anthropic Configuration (Default Provider)
# =============================================================================
# Get API key: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Model selection
# Options: claude-sonnet-4-5-20250929, claude-opus-4-5-20251101, claude-3-5-sonnet-20241022
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# Request timeout in seconds (default: 120)
ANTHROPIC_TIMEOUT=120

# =============================================================================
# OpenAI Configuration (Optional)
# =============================================================================
# Get API key: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Model selection
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo
OPENAI_MODEL=gpt-4o

# Organization ID (optional - only needed for organization accounts)
OPENAI_ORG_ID=

# Request timeout in seconds (default: 120)
OPENAI_TIMEOUT=120

# =============================================================================
# Google Gemini Configuration (Optional)
# =============================================================================
# Get API key: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# Model selection
# Options: gemini-2.5-pro, gemini-2.5-flash, gemini-2.5-flash-lite-preview-06-17, gemini-2.0-flash
GEMINI_MODEL=gemini-2.5-flash

# Request timeout in seconds (default: 120)
GEMINI_TIMEOUT=120

# =============================================================================
# Ollama Configuration (Optional - Local LLM)
# =============================================================================
# Ollama runs locally and doesn't require an API key
# Install: https://ollama.ai/download
# Server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Model selection
# Popular options: llama3.2, llama3.1, codellama, mistral, mixtral, phi3, qwen2.5
# For cloud-hosted: kimi-k2-thinking:cloud, kimi-k2-thinking, kimi-k2
OLLAMA_MODEL=llama3.2

# Alternative models for specific tasks (optional)
OLLAMA_CODE_MODEL=codellama
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Request timeout in seconds (default: 120)
OLLAMA_TIMEOUT=120

# =============================================================================
# Jira Integration (Optional)
# =============================================================================
# Enables work item tracking, sprint management, and MoSCoW prioritization
# Get API token: https://id.atlassian.com/manage-profile/security/api-tokens
JIRA_BASE_URL=https://your-domain.atlassian.net
JIRA_USERNAME=your-email@example.com
JIRA_API_TOKEN=your-jira-api-token

# =============================================================================
# Confluence Integration (Optional)
# =============================================================================
# Enables automatic documentation generation and DSDM artifact storage
# Get API token: https://id.atlassian.com/manage-profile/security/api-tokens
CONFLUENCE_BASE_URL=https://your-domain.atlassian.net
CONFLUENCE_USERNAME=your-email@example.com
CONFLUENCE_API_TOKEN=your-confluence-api-token
